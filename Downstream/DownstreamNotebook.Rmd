---
title: "Downstream Analysis Notebook"
subtitle: "StarSolo P7_8 lung"
author: "Dídac Jiménez"
date: "21-05-2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Purpose

The purpose of this notebook is to analyze the counts matrix obtained from single cell RNA sequencing raw data. The process involves quality control, scaling, dimensional reduction, clustering,differential expression analysis and a comparison with the same procedure on _ground truth_ data. I used the Seurat package which provides all the tools needed for the analysis.

## Preparation and setup

### Libraries

Load libraries used in this notebook. `Seurat` provides most of the needed functions to analyze scRNAseq data, `dplyr` is very useful for table manipulation at the end of the file, helps with the plots. The rest of libraries help with reading the count matrix files into R.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(Seurat, quietly = TRUE)
library(dplyr, quietly = T)
library(tidyverse, quietly = T)
library(Matrix, quietly = TRUE)
library(DropletUtils, quietly = TRUE)
library(ggplot2, quietly = T)
library(knitr)
```

### Set parameters and indicate paths

Indicate the preprocessing tool used, and a name for the project. The preporcessing tool name must be one of the provided after the #.

```{r}
# General variables
projectname<-"Prototype"
tool<-"UmiTools"#  "KallistoBustools", "StarSolo", UmiTools or "SalmonAlevin"
```

Next chunk saves the path to the count matrix, the list of genes and the list of cells. *This is not provided in the github* so files need to be provided to reproduce results. 

```{r}
# Dataset location
matrixpath<-"~/Work/TFM/Runs/UT_2505_78/counts.tsv.gz"
featurespath<-"/media/student/Storage/Runs/KB_2205_78/Counts/counts_unfiltered/cells_x_genes.genes.txt" #Only for KB and StarSolo
cellspath<-"/media/student/Storage/Runs/KB_2205_78/Counts/counts_unfiltered/cells_x_genes.barcodes.txt"#Only for KB and StarSolo
```

Last chunk points to the variety of accessory files needed in the analysis. To reproduce the results *set the working directory to the repository* and the *knit directory to the working directory*, then, for `tabulaMuris_anotatedTable_path` and `clusterIdents_path` choose the anotatedTable.csv and idents.csv files of the same cell dataset.

```{r}
# Accessory files
MT_genespath<-"./Refs/MTgenes.csv"
rRNA<- "./Refs/rRNA.csv"
ensemblid2description_path<-"./Refs/ensemblid2description.csv"
tabulaMuris_anotatedTable_path<-"./Refs/10X_P7_8_anotatedTable.csv" # Make sure this file is obtained from the data of the same tissue
clusterIdents_path<-"./Refs/10X_P7_8_idents.csv"
```

### Load raw files into counts matrix

Outputs from each preprocessing tool are different. I will define and use different functions to generate a counts matrix.

```{r}
if (tool == "KallistoBustools" || tool == "StarSolo"){
  counts<-ReadMtx(
    mtx = matrixpath,
    cells = cellspath,
    features = featurespath,
    cell.column = 1,
    feature.column = 1,
    cell.sep = "\t",
    feature.sep = "\t",
    skip.cell = 0,
    skip.feature = 0,
    mtx.transpose = tool == "KallistoBustools",
    unique.features = TRUE,
    strip.suffix = FALSE
)
  # Ensembl version removal
  rownames(counts)<-sub('\\.[0-9]*$', '', rownames(counts))
}

if (tool == "SalmonAlevin"){
  txi <- tximport::tximport(matrixpath, type="alevin")
  counts<-txi$counts
  # Ensembl version removal
  rownames(counts)<- sub('\\.[0-9]*$', '', rownames(txi$counts))
}

if (tool == "UmiTools"){
  source("~/Work/TFM/Code/Pipelines/umitools_to_10x.R")
  umitools_to_mtx(matrixpath, output_path = sub("counts.tsv","",matrixpath))
  counts <- Read10X(sub("counts.tsv","",matrixpath), 
                  gene.column = 1)
}
```

### Tag mitochondrial genes

Mitochondrial genes must have a tag on their name so that we can use the proportion of mitochondrial transcripts as a quality control measure. This is better done before the construction of the `Seurat` object. For this, I use a list of all mitochondrial genes in mouse previously acquired from biomart.


```{r}
#List of the names of our genes
gene_names<-data.frame(ens=rownames(counts))

# Lists generated Using Biomart from Ensembl to  create a list of ENS genes corresponding to mitochondrial genes 
MT_genes<-data.frame(MT=read.csv(MT_genespath))
rRNA<-data.frame(rNA=read.csv(rRNA))

# Loop through all gene names and tag those found in the list
MT_count <-0

for (i in 1:length(gene_names$ens)){
  if (gene_names$ens[i] %in% MT_genes$ensembl_gene_id){
    MT_count<-MT_count+1 # To check if it works
    gene_names$ens[i] <- paste(c("MT-",gene_names$ens[i]),sep="",collapse = "")
  }
}

# Change names in the raw data
row.names(counts)<-gene_names$ens # Change row names of counts matrix 
```

### Generate Seurat object

Finally I create the 'Seurat' object which we will use to proceed with the analysis. There is a small filtering involved in which we only include features detected in at least 5 cells, and only cells with at least 5 features.

```{r}
min.cells.features <- c(5,5) # CreateSeuratObject. Include features detected in at least this many cells, and cells with at least this many features
seurat.obj <- CreateSeuratObject(counts = counts, 
                                 project = "projectname", 
                                 min.cells = 5, 
                                 min.features = 5)
```

## Quality Control

### Data exploration

The first step of the downstream analysis is the quality control, which consists in manually filtering cells above or under some threshholds. Before filtering, however, I check how many cells, genes and molecules are present in the dataset which are relevant metrics for preprocessing.

```{r}
sum(seurat.obj$nCount_RNA)
length(colnames(seurat.obj))
length(rownames(seurat.obj))
```

This dataset obtained trough our `r tool` pipeline has a total of `r length(rownames(seurat.obj))` genes expressed across `r length(colnames(seurat.obj))` cells, totalling `r sum(seurat.obj$nCount_RNA)` RNA molecules.

In the second step, I compute the percentage of mitochondrial transcripts for each cell, to use in the filtering. 

```{r}
# We use the label we added earlier and add the percentage as a column in the metadata of each cell
seurat.obj[["percent.mt"]]<-PercentageFeatureSet(seurat.obj,pattern = "^MT-")
```

We then plot the three metadata values: Mitochondrial percentage, number of molecules and number of features. A good dataset should have linear relationship between number of features and number of molecules, though a plateau is fine. As for the violin plot, we will use it to set the limits for our filtering.


```{r}
VlnPlot(seurat.obj, features = c("nCount_RNA", "nFeature_RNA","percent.mt"), ncol = 5)
FeatureScatter(seurat.obj, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")+geom_smooth(method='lm')
```

### Filtering

We filter the cells by setting a limit on:
*Mitochondrial percentage: An upper limit, high values may indicate a broken nucleus, thus a compromised cell
*Number of molecules: An upper limit, very high values may indicate the droplet contained two cells
*Number of features: A lower limit, droplets with too few features may only contain environmental RNA

*These filters depend on each dataset and should be changed on each execution.* Set the lower and upper limits manually.

```{r}
nCount_threshold <- c(2000, 12000)  # subset. Minimum and maximum number of molecules detected in a cell to be kept
nFeature_threshold <- c(500, 3700) # subset. Minimum and maximum number of features detected in a cell to be kept
percent.ribo_threshold <-5 # subset. Maximum percentage of mitocondrial molecules
```

To apply the filters `Seurat` provides a method for the `subset` function, and I save it in a different object so that I can run the chunks above again to compare and fine tune the filters. 

```{r}
seurat.obj.filtered <-
  subset(
    x = seurat.obj,
    subset = nCount_RNA > nCount_threshold[1] &
      nCount_RNA < nCount_threshold[2] &
      nFeature_RNA > nFeature_threshold[1] &
      nFeature_RNA < nFeature_threshold[2] &
      percent.mt < percent.ribo_threshold
  )
```

Next I show the plots again to check the filtering:

```{r}
VlnPlot(
  seurat.obj.filtered,
  features = c("nCount_RNA", "nFeature_RNA", "percent.mt"),
  ncol = 3
)
FeatureScatter(seurat.obj.filtered,
               feature1 = "nCount_RNA",
               feature2 = "nFeature_RNA") + geom_smooth(method = 'lm')
```

```{r}
sum(seurat.obj.filtered$nCount_RNA)
length(colnames(seurat.obj.filtered))
length(rownames(seurat.obj.filtered))
```

After filtering we keep a total of `r length(rownames(seurat.obj.filtered))` genes expressed across `r length(colnames(seurat.obj.filtered))` cells, totalling `r sum(seurat.obj.filtered$nCount_RNA)` RNA molecules.

## Normalization, feature selection and scaling

### Normalization

To start this section I apply normalization to the expression values cells can be compared. Each value is divided by the total expression in its cell, multiplied by a scale factor and then log transformed.

$$
N_{ij}=log(1+M\frac{A_{ij}}{\sum_{j'}A_{ij'}}) \\
M=10⁴
$$

```{r}
seurat.obj.filtered<-NormalizeData(object=seurat.obj.filtered)
```

### Highly variable features

Next, I select the genes with high standarized log dispersion. The log dispersion $d$ of a gene $i$ with mean and variance standarized expresion $v_i,m_i$ is simply:

$$
d_i = log(v_i/m_i)
$$

The purpose is to focus the analysis on the genes that differentiate the cells. Following Tabula muris approach, we keep those genes with $d_i>0.5$ and $log(m_i)>0.1$

```{r}
seurat.obj.filtered <-
  FindVariableFeatures(
    object = seurat.obj.filtered,
    mean.cutoff = c(0.5, Inf),
    dispersion.cutoff = c(0.1, Inf)
  )
```

### Scale data

Through `ScaleData()` I shift the expression of each gene, so that the mean expression across cells is 0 and scales the expression of each gene, so that the variance across cells is 1. This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate and is a required step prior to dimensional reduction techniques.

$$X{ij}=(N_{ij}-\mu_i)/\sigma_i$$

```{r}
seurat.obj.filtered <-
  ScaleData(seurat.obj.filtered,
            vars.to.regress = c("nCount_RNA",  "percent.mt"))
```

## Dimension reduction

### Principal Component Analysis

I run the analysis with `RunPCA()` over the selected most variable genes and then project the dimensional reduction (with `ProjectDim`) onto the entire dataset so that all genes have loadings.

```{r message=FALSE}
seurat.obj.filtered <-
  RunPCA(
    seurat.obj.filtered,
    features = VariableFeatures(seurat.obj.filtered),
    ndims.print = 1
  )
seurat.obj.filtered <- ProjectDim(seurat.obj.filtered, verbose = F)
```

After PCA, to keep enough PC's to capture most of the variation I check the standard deviation of each PC and I keep those before the Elbow that appears in the plot. The PC kept will be used for clustering and t-SNE.

```{r}
ElbowPlot(seurat.obj.filtered)
```

*Chose in the next chunk the number of PC to be kept*

```{r}
n.pcs <- 13
```

### Shared Nearest Neighbor Clustering

To obtain the cluster, first, I compute the 30 nearest neighbors according in the dimensional space set by the selected PC with `FindNeighbours`. Then the clusters are identified through shared nearest neighbors with `FindClusters` and finally ploted through `DimPlot`.

```{r}
seurat.obj.filtered <-
  FindNeighbors(seurat.obj.filtered,
                dims = 1:n.pcs,
                k.param = 30)

seurat.obj.filtered <-
  FindClusters(
    seurat.obj.filtered,
    resolution = 0.1,
    random.seed = 42,
    n.start = 20,
    n.iter = 20
  )
DimPlot(
  seurat.obj.filtered ,
  dims = c(1, 2),
  reduction = "pca",
  label = TRUE
)
```

### t-Distributed Stochastic Neighbor Embedding dimensional reduction

Afterwards I compute the _t-distributed stochastic neighbor embedding_ (t-SNE) parameters. t-SNE is a dimensional reduction method that discriminates clusters really well. First, the probability proportional to similarity is calculated for each pair. For data point $x_{j}$ to data point $x_{i}$ this is the conditional probability, $p_{j|i}}$, that $x_{i}$ would pick $x_{j}$ as its neighbor if neighbors were picked in proportion to their probability density under a student t centered at $x_{i}$. Then a distribution in the lower space is computed iteratively (through gradient descent) to minimize the Kullback–Leibler divergence between it and the full dimensional distribution.

For our application, we will use Seurat's `RunTSNE`. It does not work directly on the genes as dimensions as t-SNE struggles with too many dimensions. It uses the principal components computed above, since PC are good at separating signal from noise. We need to choose a parameter named perplexity that roughly sets how much impact closer points have over points further apart.

```{r}
seurat.obj.filtered <-
  RunTSNE(
    seurat.obj.filtered,
    dims.use = 1:n.pcs,
    seed.use = 42,
    perplexity = 15,
    dim.embed = 2
  )
TSNEPlot(seurat.obj.filtered)
```

## Differential expression

The differential expression analysis can be performed with `FindAllMarkers`. This function provides a table detailing the marker genes of each cluster. Including its id, the cluster in which it is differentially expressed, the difference in expression and the metric used to find the markers. The metric used is the area under the curve (AUC). To compute it, the function builds a classifier for each combination of gene and cluster, with that gene as the only classifier and a with the cluster and the rest of cells as the two classes. To evaluate the classifier, `FindAllMarkers` returns the area under the receiver operating characteristic (ROC), which is the true positive rate against the false positive rate. Essentially measures how well the gene discriminates between the cells of cluster and the rest of cells. An AUC value of 1 means that expression values for this gene alone can perfectly classify the two groupings: _Each of the cells in the evaluated cluster exhibit a higher level of the evaluated gene than in the cells of the rest of clusters_. An AUC value of 0 also means there is perfect classification, which means that lesser expression predicts that the cell belong to the cluster. However, we will only evaluate genes that are more expressed than the average in the cluster, as we want to find marker genes and not build a classifier.

We will keep only the top 2% genes by AUC and to speed up the process we will only test genes that are detected at minimum in 10% of cells.

```{r}
markers <-
  FindAllMarkers(
    object = seurat.obj.filtered,
    test.use = "roc",
    only.pos = TRUE,
    min.pct = 0.1,
    return.thresh = 0.02
  )
rownames(markers) <- c()
```

Next chunk shows the top 5 genes of each cluster for report completion through some table manipulation. We add the description of each gene through a file previously obtained from Biomart which is available in the github.

```{r}
ensemblid2description <- read.csv(ensemblid2description_path)
anotated_table <- data.frame()
for (i in unique(markers$cluster)) {
  markers %>%
    dplyr::select(gene, cluster, myAUC, avg_log2FC) %>%
    filter(cluster == i) %>%
    top_n(5, myAUC) %>%
    left_join(ensemblid2description, by = "gene") ->    cluster
  anotated_table <- rbind(anotated_table, cluster)
}

knitr::kable(anotated_table)
```

## Comparisons

### Comparing marker genes of each cluster

To compare the marker genes of the cluster computed in this notebook, and those from the ground truth. I read the anotated table obtained from the data preprocessed by Tabula Muris. I perform an inner join with the description to figure which clusters are equivalent. Not on the keys because while the preprocessing pipelines of this project output the gene names as Ensembl stable IDs, the tabula muris project provides its files with HGNC symbols.

```{r}
anotated_table <- data.frame()
for(i in unique(markers$cluster)){
  markers %>% 
    dplyr::select(gene, cluster, myAUC, avg_log2FC) %>% 
    filter(cluster ==i) %>%
    top_n(10, myAUC) %>%
    left_join(ensemblid2description, by = "gene") -> cluster
    anotated_table <- rbind(anotated_table, cluster)
}
tabulaMuris_anotatedTable <- read.csv(tabulaMuris_anotatedTable_path)
anotated_table %>% inner_join(tabulaMuris_anotatedTable, by="description") %>% dplyr::select(gene.y, description, cluster.x, cluster.y, myAUC.x, avg_log2FC.x) %>% knitr::kable(col.names = c("Gene", "Description", "Cluster of project", "Ground truth cluster", "myAUC", "avg_log2FC"))
```

### Comparing cell identities

Lastly, I want to compare directly how many cells are in the same cluster both from Tabula Muris data and from our data. For that, I read the .csv with the cluster of each barcode from tabula muris and i compute the same dataframe.

```{r}
idents_TM <- read.csv(clusterIdents_path)
idents <- as.data.frame(seurat.obj.filtered$seurat_clusters)
idents <- as.data.frame(cbind(rownames(idents),idents$`seurat.obj.filtered$seurat_clusters`))
names(idents)=c("CellBarcodes", "Cluster")
```

```{r}
sum(idents_TM[,1] %in% idents[,1])
```

A total of `r sum(idents_TM[,1] %in% idents[,1])` cells that passed the filters coincide with those that passed the filters of the ground truth, from a total of `r length(colnames(seurat.obj.filtered))` that passed the filters.

```{r}
idents %>% inner_join(idents_TM, "CellBarcodes") %>% count_(c("Cluster.x", "Cluster.y")) %>% arrange(desc(n))
```

From this table we can check if most cells from a given Tabula Muris cluster are all in the same cluster (it might not have the same label) in our data.




